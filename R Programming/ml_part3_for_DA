library(tidyverse)
library(caret)
library(mlbench)

## load data
data("PimaIndiansDiabetes")

df<- PimaIndiansDiabetes

mean(complete.cases(df))

## train model
## recursive partitioning(desicion tree)
#rpart
ctrl = trainControl(
  method = "cv",
  number = 5,
  verboseIter = TRUE,
  classProbs = TRUE, # we can change threshold 0.5
  summaryFunction = twoClassSummary
)

tree_model <- train(
  diabetes ~ .,
  data = df,
  method = "rpart",
  metric = "ROC",
  trControl = ctrl
)

##prediction
predict(tree_model,df,type = "prob")[1:10,]

## change threshold 
probs <- predict(tree_model,df,type = "prob")

p_class <- ifelse(probs$pos >= 0.5,"pos","neg")

table(df$diabetes,p_class)

## random forest(bagging)
#rf
ctrl = trainControl(
  method = "cv",
  number = 5,
  verboseIter = TRUE

)

rf_model <- train(
  diabetes ~ .,
  data = df,
  method = "rf",#ranger
  metric = "Accuracy",
  tuneGrid = data.frame(mtry = c(2,3,4)),
  trControl = ctrl
)


## RF win rate Decision Tree 95%

## Rige vs.Lasso REgression
##Regularizatopn
## Rige => beta will be lower,but not zero
## Lasso => beta can be zero(farture selection)

glmnet_model <- train(
  diabetes ~ .,
  data = df,
  method = "glmnet",#ranger
  metric = "Accuracy",
  tuneGrid = expand.grid(
    alpha = 0:1,
    lambda = c(0.004,0.04,0.08)
  ),
  trControl = ctrl
)

## save model
saveRDS(glmnet_model,"ride_lasso_reg.RDS")
     
